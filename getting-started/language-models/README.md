---
icon: language
layout:
  width: default
  title:
    visible: true
  description:
    visible: true
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
  metadata:
    visible: true
---

# Language Models

<table data-card-size="large" data-view="cards" data-full-width="true"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-cover data-type="image">Cover image</th><th data-hidden data-card-target data-type="content-ref"></th></tr></thead><tbody><tr><td><strong>Deepseek</strong></td><td>Open-weight, cost-efficient MoE models with strong chain-of-thought reasoning; R1 rivals top models and all are open-source under MIT.</td><td><mark style="color:$success;">DeepSeek-LLM / V2 / V3 / R1 / R1-Distill</mark></td><td><a href="../../.gitbook/assets/deepseek-1080.svg">deepseek-1080.svg</a></td><td><a href="deepseek.md">deepseek.md</a></td></tr><tr><td><strong>Qwen (Alibaba Cloud)</strong></td><td>Multimodal, open-licensed (Apache-2.0) LLM family with enterprise integration, strong reasoning and flexibility via dense and sparse architectures.</td><td><mark style="color:$success;">Qwen 3 / Qwen 2.5 / Qwen 2</mark></td><td><a href="../../.gitbook/assets/qwen-1080.svg">qwen-1080.svg</a></td><td><a href="qwen.md">qwen.md</a></td></tr><tr><td><strong>OpenAI</strong></td><td>Apache-2.0 licensed MoE open-weight models (120B &#x26; 20B); efficient, long-context, reasoning-focused; consumer hardware-friendly, on par with OpenAI’s internal models</td><td><mark style="color:$success;">gpt-oss (20B and 120B)</mark></td><td><a href="../../.gitbook/assets/openai-1080.svg">openai-1080.svg</a></td><td><a href="openai.md">openai.md</a></td></tr><tr><td><strong>Meta</strong></td><td>A sequence of accessible LLMs (Llama 1 → 4) featuring instruction-tuning, multimodal MoE designs (up to ~2T params), and multilingual capabilities, released under Meta’s community license.</td><td><mark style="color:$success;">Llama series</mark></td><td><a href="../../.gitbook/assets/meta-1080.svg">meta-1080.svg</a></td><td><a href="meta.md">meta.md</a></td></tr><tr><td>Mistral AI</td><td>Efficient, open-weight LLMs, including instruction-tuned, MoE, reasoning, and code-specialist models - under Apache 2.0 licensing.</td><td><mark style="color:$success;">Mistral series</mark></td><td><a href="../../.gitbook/assets/mistral-1080.svg">mistral-1080.svg</a></td><td><a href="mistral-ai.md">mistral-ai.md</a></td></tr><tr><td><strong>Google Deepmind - Gemma</strong></td><td>Lightweight and multimodal open LLMs from 270M to 27B parameters, optimized for long context, on-device use, and efficient inference.</td><td><mark style="color:$success;">Gemma series</mark></td><td><a href="../../.gitbook/assets/deepmind-1080.svg">deepmind-1080.svg</a></td><td><a href="deepmind-gemma.md">deepmind-gemma.md</a></td></tr></tbody></table>
